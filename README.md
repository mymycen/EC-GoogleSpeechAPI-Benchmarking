<b><H1>Google Cloud Speech API Recognition

The goal here is to evaluate some automatic speech recognition (ASR) systems for English and French.


<b>Downloading Data Sources

After downloading, we downsampled the data sources to 16000 Hz and 8000 Hz. We chose "sox" for that purpose.

    $ sox Dataset/En/sampleInput01.wav -r 8000 Dataset/En/sampleOutput01.wav

Voxforge has many files, but in this benchmark, we also used another source to get clean and noisy audio files. Totally, 100 files were randomly sampled from those sources and used in the evaluation. 

The chosen sources are listed in:

    http://www.voxforge.org/home/downloads

    https://datashare.is.ed.ac.uk/handle/10283/2791

Then, those files were added to the buckets in Google Cloud Platform and set to publicly accessible.


<b>Dependencies

For this project, we needed Python and gcloud libraries to run the benchmark scripts. We used "transcribe.py" for using Google Speech API to transfrom audio files to written format.

As an example;

    $ ~/python-docs-samples/speech/cloud-client$ python transcribe.py gs://asraudiofiles/Noisy_Eng8+16/Clear/16K_Clean/p257_245.wav  

    Transcript: I will not allow destruction of the Scottish fishing industry

After running this command, we had to reformat output text file to make it compatible with Kaldi ToolKit. As you can see in the repo, we have 2 different file formats which are hypothesis(.hyp) and reference(.ref). We used those files for the comparison and calculation of WER (Word Error Rate) and SER (Sentence Error Rate) with using Kaldi. 

Hypothesis(.hyp) - The output file which stores all the results from the last command. Transcripts that are generated by Google Speech API were added to .hyp file  

Reference(.ref) - The file which is obtained from the data source. It contains original transcription of the audio files.

Kaldi can do the comparison and the calculation of the error rates based on the differences among those files.

Example:

    $ ./transformData.sh En/hypothesis_EN.tra > En/hypothesis.hyp
    $ ./transformData.sh En/Reference_EN.tra > En/reference.ref

<b>Benchmark

In this benchmark, word error rate (WER) and sentence error rate (SER) were be evaluated for analysis of noisy and clean audio sources and we used Kaldi toolKit to measure them. 


English Audio File - 8000Hz

    compute-wer --mode=present ark:Reference_EN.ref ark:hypothesis_EN8K.hyp



English Audio File - 16000Hz

    compute-wer --mode=present ark:Reference_EN.ref ark:hypothesis_EN16K.hyp


French Audio File - 8000Hz

    compute-wer --mode=present ark:Reference/Reference_FR.ref ark:Hypothesis/Hypothesis_FR8K.hyp


French Audio File - 16000Hz

    compute-wer --mode=present ark:Reference/Reference_FR.ref ark:Hypothesis/Hypothesis_FR16K.hyp


English Audio Files (Noisy Format) - 8000Hz

    compute-wer --mode=present ark:Reference_EN_NoisyData.ref ark:Hypothesis_Noisy8K.hyp


English Audio Files (Noisy Format) - 16000Hz

    compute-wer --mode=present ark:Reference_EN_NoisyData.ref ark:Hypothesis_Noisy16K.hyp

English Audio Files (Noiseless Format) - 8000Hz
    
    compute-wer --mode=present ark:Reference_EN_clean.ref ark:Hypothesis_En8K_clean.hyp

English Audio Files (Noiseless Format) - 16000Hz
    
    compute-wer --mode=present ark:Reference_EN_clean.ref ark:Hypothesis_En16K_clean.hyp

<b>Results


Results shown in terms of WER (Word Error Rate) and SER (Sentence Error Rate).


    English Audio - 8000Hz
    %WER 17.13 [ 99 / 578, 12 ins, 16 del, 71 sub ]%SER 78.00 [ 39 / 50 ]Scored 50 sentences, 0 not present in hyp.

    English Audio - 16000Hz
    %WER 14.71 [ 85 / 578, 5 ins, 9 del, 71 sub ]%SER 60.00 [ 30 / 50 ]Scored 50 sentences, 0 not present in hyp.

    French Audio - 8000Hz
    %WER 21.87 [ 124 / 567, 6 ins, 15 del, 103 sub ]%SER 84.00 [ 42 / 50 ]Scored 50 sentences, 0 not present in hyp.

    French Audio - 16000Hz
    %WER 17.99 [ 102 / 567, 5 ins, 10 del, 87 sub ]%SER 80.00 [ 40 / 50 ]Scored 50 sentences, 0 not present in hyp.

    English Noisy - 8000Hz
    %WER 24.58 [ 29 / 118, 1 ins, 5 del, 23 sub ]%SER 80.00 [ 8 / 10 ]Scored 10 sentences, 0 not present in hyp.

    English Noisy - 16000Hz
    %WER 16.10 [ 19 / 118, 0 ins, 6 del, 13 sub ]%SER 70.00 [ 7 / 10 ]Scored 10 sentences, 0 not present in hyp.
    
    English Noiseless - 8000Hz
    %WER 10.26 [ 12 / 117, 1 ins, 3 del, 8 sub ]%SER 40.00 [ 4 / 10 ]Scored 10 sentences, 0 not present in hyp.
    
    English Noiseless - 16000Hz
    %WER 9.40 [ 11 / 117, 1 ins, 5 del, 5 sub ]%SER 40.00 [ 4 / 10 ]Scored 10 sentences, 0 not present in hyp.


These are the results in 28/January/2018. The system may be upgraded along the time and these rates may change.

**Benchmark Results Plot**
![Sheet_2-_FINAL](/uploads/55cb39e00a5aec2c4587c10a39ff444b/Sheet_2-_FINAL.png)
![Webp.net-resizeimage__3_](/uploads/8b02915c378f437cdd8aae566be4cad0/Webp.net-resizeimage__3_.png)
![Sheet_3_-_FINAL](/uploads/7c51d2f82ce9776f7587873a209a388c/Sheet_3_-_FINAL.png)

For detailed report on this experiment, check out the wiki page of this repository.
https://gitlab.tubit.tu-berlin.de/leonav/EC-GoogleSpeechAPI-Benchmarking/wikis/home


